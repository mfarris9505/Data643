{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tackling Cold-Start User and Items in Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though collaborative filtering techniques have been throughly and comprehensively validated, a problem has remained that is still at the forefront of research, and that is the cold-start problem. Conceptually, cold-start problems are at the fore-front of the business world. With new users, we face the age old adage of whether finding new customers is more costly than retaining old ones. We all know that such is the case from previous statistic, however, in the emerging world of online retail and \"subscription\" services, though it may cost more to find new customers, without significant growth, most of these companies will become stagnant, and in the end be quickly replaced by the next big internet fad. This is why the cold-start problem has been a big priority for companies such as Netflix, Amazon, and any other online retailer or subscription service. By being able to provide new users with accurate recommendation could easily increase sales and ensure that \"free-trial members\" become full fledged paying users. Our focus in this project will be how to tackle these cold start user and items. The plan for this project will be to utilize several different techniques to determine which method is the best. Our choice for the moment would be the previously explored SVD factorization, along with a new alternating least squared method. Furthermore, the idea of a \"weighting system\" will be implemented using the content of movie and user data. The idea here, will be to apply a cold-start for a user, by assigning that users rating as the average rating of all the items by all the users, finding the users with similar attributes, and then applying a weight to those averages to determine a \"predicted value.\" This will be tested against the RMSE of his actual predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Source and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project we will continue to use the MovieLens data source. Though in all reality, we could move on to any another dataset, but the proposed implementation can be easily modified for any dataset. In order to save time, and because ther Movie-lens data set is tried and tested, we continued to use the 100k movieset. Furthermore, the entire dataset will be used in this implementation. As we plan to utilize the content of the items and the users, we will creating a similiarity matrix for the content matrix. The purpose of this would be to create a weighting system for Collaborative Filtering, allowing for a \"boost\" in the accuracy [1]. Furthermore, our plan is to use some of the User data to create implied \"context\" data [4] because the data set does not have any explicite data, we will apply some pre-filtering data from the implied content informaiton. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposed Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our proposed project, we will combined previous projects as a standard \"background\" recommender system and base code. From there we plan to create and devise a new system using the following steps: \n",
    "* Data Acquistion and Normaliation\n",
    "    * The first step of this process will be to process the data. For the data will be organized into 3 matrices, a User-content matrix, an Item-Content Matrix and a User-Item Rating matrix. For the movie and User content matrices, each row will represent an movie or user, respectively, while the columns will represent a specific aspect of the movie or user. For istances, all the movie break downs will be either 0 or 1, indicating if it belongs to a specific genre (19 in total). For the users, each column will represnt a specific age range the belong to, their gender, and their occupation. Furthermore, the location will be included, however, it will be utilized only as a means of providing some contextual basis. \n",
    "    * Using the designated packages in python, normalization techniques will be applied to the Rating Matrix only.For this process, we are borrowing normalization techniques from Nguyen et. al [1]. The plan is to implement an ANOVA style normalization technique (time permitting) as opposed to a standard mean-centered approach. Furthermore, in order to eliminate sparcity for this project we will consider taking a step that was peformed in the previous experiment where we filled \n",
    "* Matrix Factorization\n",
    "    * For our purposes here, we will conduct several different factorization techniques and apply them to the dataset. The first being the SVD applied in the last project. We will then implement a new factorization technique using Alternating least squares. Bugra [5] proposes a way to calculate the least squares in python. Some of the code will be adpated from his work. In each of these cases we will obtain a similarity matrix for User-User and Item-Item for each technique. \n",
    "* Content-Based Filtering Weighting\n",
    "    * Several Articles have proposed a weighting system. Nguyen et. al [1] proposes a formula to extract an alignment penalty.  I propose another idea, where after obtaining the Item -Item or User-User similarity matrix, rather than using the nearest neighbor as done previously, I propose to take the nearest neighbors from the rating that corresponds to most similar item/user from the content matrix. The code will be built to find all the nearest neighbors from the similarity matrix, and the correspond that to the content matrix. Another possibility would be to create a relative weight for each of the nearest neighbors.(I am still investigate how this will be done as the proposed weighting system from Nguyen et. al [1] requires gradient descent, an attempt will be made at this, but time is a factor). \n",
    "* Evaluation\n",
    "    * This will be evaluated by utilizing the RMSE. We will take a training set, and a testing set, where we remove all the values user ratings. We will use this testing set as away to calculate the RMSE of the actual vs. predicted values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1]Nguyen, J., and Zhu, M.  Content-boosted matrix factorization techniques for recommender systems. *Statistical\n",
    "Analysis and Data Mining* 2013: 6(4):286–301. https://arxiv.org/pdf/1210.5631.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2]Vozalis, M. and Margaritis K.; Applying SVD on Generalized Item-based Filtering *International Journal of Computer Science & Applications* 2006; Vol.3 Is.3, pp 27- 51 http://www.tmrfindia.org/ijcsa/v3i34.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3]Harper, F.M. and Konstan, J.; *The MovieLens Datasets: History and Context.* ACM Transactions on Interactive Intelligent Systems (TiiS) 2015: 5, 4, Article 19, 19 pages. http://dx.doi.org/10.1145/2827872 http://grouplens.org/datasets/movielens/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4]G. Adomavicius, A. Tuzhilin, Context-Aware recommender Systems, *in: F. Ricci, et al. (Ed.), Recommender Systems Handbook*, 2011, pp. 217–253. http://ids.csom.umn.edu/faculty/gedas/nsfcareer/CARS-chapter-2010.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[5] Bugra, A. Alternating Least Squares Method for Collaborative Filtering *Bugra Machine Learning Newletter* 2014 http://bugra.github.io/work/notes/2014-04-19/alternating-least-squares-method-for-collaborative-filtering/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
